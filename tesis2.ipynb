{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4WzqttbYcd_S"
   },
   "source": [
    "Este es un cuaderno complementario del libro [Aprendizaje profundo con Python, segunda edición](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qs4h7Aq0cd_Z"
   },
   "source": [
    "## Traduccion automatica usando transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PrTCahq6jrHZ",
    "outputId": "25a12e5e-fc17-479f-ebdf-11051121c3bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-12-26 13:36:21--  http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.145.128, 108.177.126.128, 108.177.127.128, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.145.128|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2638744 (2.5M) [application/zip]\n",
      "Saving to: ‘spa-eng.zip’\n",
      "\n",
      "\r",
      "spa-eng.zip           0%[                    ]       0  --.-KB/s               \r",
      "spa-eng.zip         100%[===================>]   2.52M  --.-KB/s    in 0.01s   \n",
      "\n",
      "2022-12-26 13:36:21 (178 MB/s) - ‘spa-eng.zip’ saved [2638744/2638744]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
    "!unzip -q spa-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6q51BckS2ITE"
   },
   "outputs": [],
   "source": [
    "model.save('path_to_my_model.h5')\n",
    "new_model = keras.models.load_model('path_to_my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bt6GOdGMtir9"
   },
   "outputs": [],
   "source": [
    "text_file = \"spa-eng/spa.txt\" \n",
    "with open(text_file) as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "text_pairs = [] \n",
    "for line in lines:\n",
    "    english, spanish = line.split(\"\\t\")\n",
    "    spanish = \"[start] \" + spanish + \" [end]\"\n",
    "    text_pairs.append((english, spanish))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cRYOYm5DxcV0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet('test-00000-of-00001.parquet')\n",
    "df.to_csv('test.txt',columns=[\"es\"],index=False,sep='\\t')   # Alternatively, you can use tab separators\n",
    "df = pd.read_parquet('validation-00000-of-00001.parquet')\n",
    "df.to_csv('validation.txt', columns=[\"es\"],index=False,sep='\\t')   # Alternatively, you can use tab separators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SsENvBA2wEsr"
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet('train-00000-of-00001.parquet')\n",
    "df[:10000].to_csv('train1.txt', columns=[\"es\"], index=False, sep='\\t')   # Alternatively, you can use tab separators\n",
    "df[10000:20000].to_csv('train2.txt', columns=[\"es\"], index=False, sep='\\t')   # Alternatively, you can use tab separators\n",
    "df[20000:30000].to_csv('train3.txt', columns=[\"es\"], index=False, sep='\\t')   # Alternatively, you can use tab separators\n",
    "df[30000:40000].to_csv('train4.txt', columns=[\"es\"], index=False, sep='\\t')   # Alternatively, you can use tab separators\n",
    "df[40000:50000].to_csv('train5.txt', columns=[\"es\"], index=False, sep='\\t')   # Alternatively, you can use tab separators\n",
    "df[50000:60000].to_csv('train6.txt', columns=[\"es\"], index=False, sep='\\t')   # Alternatively, you can use tab separators\n",
    "df[60000:70000].to_csv('train7.txt', columns=[\"es\"], index=False, sep='\\t')   # Alternatively, you can use tab separators\n",
    "df[70000:80000].to_csv('train8.txt', columns=[\"es\"], index=False, sep='\\t')   # Alternatively, you can use tab separators\n",
    "df[80000:90000].to_csv('train9.txt', columns=[\"es\"], index=False, sep='\\t')   # Alternatively, you can use tab separators\n",
    "df[90000:100000].to_csv('train10.txt', columns=[\"es\"], index=False, sep='\\t')   # Alternatively, you can use tab separators\n",
    "df[100000:].to_csv('train11.txt', columns=[\"es\"], index=False, sep='\\t')   # Alternatively, you can use tab separators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vwKtNcCJrIEt"
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet('train-00000-of-00001.parquet')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lueq198LP5V6"
   },
   "outputs": [],
   "source": [
    "text_file = \"train.txt\" \n",
    "with open(text_file) as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "train_pairs = [] \n",
    "for line in lines:\n",
    "    english, spanish = line.split(\"\\t\")\n",
    "    spanish = \"[start] \" + spanish + \" [end]\"\n",
    "    train_pairs.append((english, spanish))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4vDBrVzbjjzr"
   },
   "outputs": [],
   "source": [
    "text_file = \"test.txt\" \n",
    "with open(text_file) as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "test_pairs = [] \n",
    "for line in lines:\n",
    "    english, spanish = line.split(\"\\t\")\n",
    "    spanish = \"[start] \" + spanish + \" [end]\"\n",
    "    test_pairs.append((english, spanish))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z--XG7p7jjpy"
   },
   "outputs": [],
   "source": [
    "text_file = \"validation.txt\" \n",
    "with open(text_file) as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "val_pairs = [] \n",
    "for line in lines:\n",
    "    english, spanish = line.split(\"\\t\")\n",
    "    spanish = \"[start] \" + spanish + \" [end]\"\n",
    "    val_pairs.append((english, spanish))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zimLnEeVcd_b"
   },
   "source": [
    "### Recoleccion de datos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "-Um9u-Dnr6zH"
   },
   "outputs": [],
   "source": [
    "train_pairs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "9jxZo1fAvIFX"
   },
   "outputs": [],
   "source": [
    "text_file1 = \"Data/train1Es.txt\" \n",
    "text_file2 = \"Data/train1Qu.txt\"\n",
    "\n",
    "with open(text_file1,encoding=\"utf-8\") as f:\n",
    "    lines1 = f.read().split(\"\\n\")[:-1]\n",
    "with open(text_file2,encoding=\"utf-8\") as f:\n",
    "    lines2 = f.read().split(\"\\n\")[:-1]\n",
    "\n",
    "for i in range(0,len(lines2)):\n",
    "    español  = lines1[i]\n",
    "    quechua  = lines2[i]\n",
    "    if español != quechua:\n",
    "       quechua = \"[start] \" + quechua + \" [end]\"\n",
    "       train_pairs.append((español, quechua))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "4CSb4W2jsBsZ"
   },
   "outputs": [],
   "source": [
    "text_file1 = \"Data/train2Es.txt\" \n",
    "text_file2 = \"Data/train2Qu.txt\"\n",
    "\n",
    "with open(text_file1,encoding=\"utf-8\") as f:\n",
    "    lines1 = f.read().split(\"\\n\")[:-1]\n",
    "with open(text_file2,encoding=\"utf-8\") as f:\n",
    "    lines2 = f.read().split(\"\\n\")[:-1]\n",
    "\n",
    "for i in range(0,len(lines2)):\n",
    "    español  = lines1[i]\n",
    "    quechua  = lines2[i]\n",
    "    if español != quechua:\n",
    "       quechua = \"[start] \" + quechua + \" [end]\"\n",
    "       train_pairs.append((español, quechua))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "oRiop2BBsCmK"
   },
   "outputs": [],
   "source": [
    "text_file1 = \"Data/train3Es.txt\" \n",
    "text_file2 = \"Data/train3Qu.txt\"\n",
    "\n",
    "with open(text_file1,encoding=\"utf-8\") as f:\n",
    "    lines1 = f.read().split(\"\\n\")[:-1]\n",
    "with open(text_file2,encoding=\"utf-8\") as f:\n",
    "    lines2 = f.read().split(\"\\n\")[:-1]\n",
    "\n",
    "for i in range(0,len(lines2)):\n",
    "    español  = lines1[i]\n",
    "    quechua  = lines2[i]\n",
    "    if español != quechua:\n",
    "       quechua = \"[start] \" + quechua + \" [end]\"\n",
    "       train_pairs.append((español, quechua))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "H4SbdKCfsDVW"
   },
   "outputs": [],
   "source": [
    "text_file1 = \"Data/train4Es.txt\" \n",
    "text_file2 = \"Data/train4Qu.txt\"\n",
    "\n",
    "with open(text_file1,encoding=\"utf-8\") as f:\n",
    "    lines1 = f.read().split(\"\\n\")[:-1]\n",
    "with open(text_file2,encoding=\"utf-8\") as f:\n",
    "    lines2 = f.read().split(\"\\n\")[:-1]\n",
    "\n",
    "for i in range(0,len(lines2)):\n",
    "    español  = lines1[i]\n",
    "    quechua  = lines2[i]\n",
    "    if español != quechua:\n",
    "       quechua = \"[start] \" + quechua + \" [end]\"\n",
    "       train_pairs.append((español, quechua))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "LtNG4osssEHH"
   },
   "outputs": [],
   "source": [
    "text_file1 = \"Data/train5Es.txt\" \n",
    "text_file2 = \"Data/train5Qu.txt\"\n",
    "\n",
    "with open(text_file1,encoding=\"utf-8\") as f:\n",
    "    lines1 = f.read().split(\"\\n\")[:-1]\n",
    "with open(text_file2,encoding=\"utf-8\") as f:\n",
    "    lines2 = f.read().split(\"\\n\")[:-1]\n",
    "\n",
    "for i in range(0,len(lines2)):\n",
    "    español  = lines1[i]\n",
    "    quechua  = lines2[i]\n",
    "    if español != quechua:\n",
    "       quechua = \"[start] \" + quechua + \" [end]\"\n",
    "       train_pairs.append((español, quechua))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "XD-lqFXhsE0p"
   },
   "outputs": [],
   "source": [
    "text_file1 = \"Data/train6Es.txt\" \n",
    "text_file2 = \"Data/train6Qu.txt\"\n",
    "\n",
    "with open(text_file1,encoding=\"utf-8\") as f:\n",
    "    lines1 = f.read().split(\"\\n\")[:-1]\n",
    "with open(text_file2,encoding=\"utf-8\") as f:\n",
    "    lines2 = f.read().split(\"\\n\")[:-1]\n",
    "\n",
    "for i in range(0,len(lines2)):\n",
    "    español  = lines1[i]\n",
    "    quechua  = lines2[i]\n",
    "    if español != quechua:\n",
    "       quechua = \"[start] \" + quechua + \" [end]\"\n",
    "       train_pairs.append((español, quechua))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "SGpOVmKzsFnO"
   },
   "outputs": [],
   "source": [
    "text_file1 = \"Data/train7Es.txt\" \n",
    "text_file2 = \"Data/train7Qu.txt\"\n",
    "\n",
    "with open(text_file1,encoding=\"utf-8\") as f:\n",
    "    lines1 = f.read().split(\"\\n\")[:-1]\n",
    "with open(text_file2,encoding=\"utf-8\") as f:\n",
    "    lines2 = f.read().split(\"\\n\")[:-1]\n",
    "\n",
    "for i in range(0,len(lines2)):\n",
    "    español  = lines1[i]\n",
    "    quechua  = lines2[i]\n",
    "    if español != quechua:\n",
    "       quechua = \"[start] \" + quechua + \" [end]\"\n",
    "       train_pairs.append((español, quechua))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "OUZvCFH-sGV1"
   },
   "outputs": [],
   "source": [
    "text_file1 = \"Data/train8Es.txt\" \n",
    "text_file2 = \"Data/train8Qu.txt\"\n",
    "\n",
    "with open(text_file1,encoding=\"utf-8\") as f:\n",
    "    lines1 = f.read().split(\"\\n\")[:-1]\n",
    "with open(text_file2,encoding=\"utf-8\") as f:\n",
    "    lines2 = f.read().split(\"\\n\")[:-1]\n",
    "\n",
    "for i in range(0,len(lines2)):\n",
    "    español  = lines1[i]\n",
    "    quechua  = lines2[i]\n",
    "    if español != quechua:\n",
    "       quechua = \"[start] \" + quechua + \" [end]\"\n",
    "       train_pairs.append((español, quechua))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "xtCEB-Z-sHCX"
   },
   "outputs": [],
   "source": [
    "text_file1 = \"Data/train9Es.txt\" \n",
    "text_file2 = \"Data/train9Qu.txt\"\n",
    "\n",
    "with open(text_file1,encoding=\"utf-8\") as f:\n",
    "    lines1 = f.read().split(\"\\n\")[:-1]\n",
    "with open(text_file2,encoding=\"utf-8\") as f:\n",
    "    lines2 = f.read().split(\"\\n\")[:-1]\n",
    "\n",
    "for i in range(0,len(lines2)):\n",
    "    español  = lines1[i]\n",
    "    quechua  = lines2[i]\n",
    "    if español != quechua:\n",
    "       quechua = \"[start] \" + quechua + \" [end]\"\n",
    "       train_pairs.append((español, quechua))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "lpCWPtcBsH34"
   },
   "outputs": [],
   "source": [
    "text_file1 = \"Data/train10Es.txt\" \n",
    "text_file2 = \"Data/train10Qu.txt\"\n",
    "\n",
    "with open(text_file1,encoding=\"utf-8\") as f:\n",
    "    lines1 = f.read().split(\"\\n\")[:-1]\n",
    "with open(text_file2,encoding=\"utf-8\") as f:\n",
    "    lines2 = f.read().split(\"\\n\")[:-1]\n",
    "\n",
    "for i in range(0,len(lines2)):\n",
    "    español  = lines1[i]\n",
    "    quechua  = lines2[i]\n",
    "    if español != quechua:\n",
    "       quechua = \"[start] \" + quechua + \" [end]\"\n",
    "       train_pairs.append((español, quechua))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "4y8-aBYcsIjv"
   },
   "outputs": [],
   "source": [
    "text_file1 = \"Data/train11Es.txt\" \n",
    "text_file2 = \"Data/train11Qu.txt\"\n",
    "\n",
    "with open(text_file1,encoding=\"utf-8\") as f:\n",
    "    lines1 = f.read().split(\"\\n\")[:-1]\n",
    "with open(text_file2,encoding=\"utf-8\") as f:\n",
    "    lines2 = f.read().split(\"\\n\")[:-1]\n",
    "\n",
    "for i in range(0,len(lines2)):\n",
    "    español  = lines1[i]\n",
    "    quechua  = lines2[i]\n",
    "    if español != quechua:\n",
    "       quechua = \"[start] \" + quechua + \" [end]\"\n",
    "       train_pairs.append((español, quechua))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "ROOZC_PsOhmg"
   },
   "outputs": [],
   "source": [
    "text_file1 = \"Data/validationEs.txt\" \n",
    "text_file2 = \"Data/validationQu.txt\"\n",
    "\n",
    "with open(text_file1,encoding=\"utf-8\") as f:\n",
    "    lines1 = f.read().split(\"\\n\")[:-1]\n",
    "with open(text_file2,encoding=\"utf-8\") as f:\n",
    "    lines2 = f.read().split(\"\\n\")[:-1]\n",
    "##text_pairs = [] \n",
    "val_pairs = []\n",
    "\n",
    "for i in range(0,len(lines2)):\n",
    "    español  = lines1[i]\n",
    "    quechua  = lines2[i]\n",
    "    if español != quechua:\n",
    "       quechua = \"[start] \" + quechua + \" [end]\"\n",
    "       ##text_pairs.append((español, quechua))\n",
    "       val_pairs.append((español, quechua))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "UiUTSvz5OuEA"
   },
   "outputs": [],
   "source": [
    "text_file1 = \"Data/testEs.txt\" \n",
    "text_file2 = \"Data/testQu.txt\"\n",
    "\n",
    "with open(text_file1,encoding=\"utf-8\") as f:\n",
    "    lines1 = f.read().split(\"\\n\")[:-1]\n",
    "with open(text_file2,encoding=\"utf-8\") as f:\n",
    "    lines2 = f.read().split(\"\\n\")[:-1]\n",
    "##text_pairs = [] \n",
    "test_pairs = []\n",
    "\n",
    "for i in range(0,len(lines2)):\n",
    "    español  = lines1[i]\n",
    "    quechua  = lines2[i]\n",
    "    if español != quechua:\n",
    "       quechua = \"[start] \" + quechua + \" [end]\"\n",
    "       ##text_pairs.append((español, quechua))\n",
    "       test_pairs.append((español, quechua))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102285"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HpjUJxs20HwI",
    "outputId": "9fad1d53-dbb7-450f-956a-b2417d2405da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Al contrario, anímelos y felicítelos.', '[start] Aswanpas kallpachay hinaspa felicitay. [end]')\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "print(random.choice(train_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "aaJ6SZvocd_h"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_pairs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-5b985ea3057f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_pairs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mnum_val_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.15\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_pairs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnum_train_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_pairs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_val_samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrain_pairs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext_pairs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnum_train_samples\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text_pairs' is not defined"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.shuffle(text_pairs)\n",
    "num_val_samples = int(0.15 * len(text_pairs))\n",
    "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
    "train_pairs = text_pairs[:num_train_samples]\n",
    "val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n",
    "test_pairs = text_pairs[num_train_samples + num_val_samples:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oGx4oyiycd_i"
   },
   "source": [
    "**Vectorizando los pares de texto en español y quechua**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "Zujffb7pcd_j"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import string\n",
    "import re\n",
    "\n",
    "strip_chars = string.punctuation + \"¿\"\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "##Convierte las letras mayusculas en minusculas\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string) \n",
    "    return tf.strings.regex_replace(\n",
    "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n",
    "\n",
    "vocab_size = 15000   #Tamaño máximo del vocabulario para esta capa.\n",
    "sequence_length = 20  #dimension de la salida\n",
    "\n",
    "source_vectorization = layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "target_vectorization = layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length + 1,\n",
    " #  standardize=\"lower_and_strip_punctuation\",\n",
    "    standardize=custom_standardization,\n",
    ")\n",
    "train_spanish_texts = [pair[0] for pair in train_pairs]\n",
    "train_quechua_texts = [pair[1] for pair in train_pairs]\n",
    "source_vectorization.adapt(train_spanish_texts)\n",
    "target_vectorization.adapt(train_quechua_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jQVjJY_vcd_l"
   },
   "source": [
    "**Preparando conjuntos de datos para la tarea de traducción**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "3f2AkldScd_m"
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "def format_dataset(spa, que):\n",
    "    spa = source_vectorization(spa)\n",
    "    que = target_vectorization(que)\n",
    "    return ({\n",
    "        \"español\": spa,\n",
    "        \"quechua\": que[:, :-1],\n",
    "    }, que[:, 1:])\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    spa_texts, que_texts = zip(*pairs)\n",
    "    spa_texts = list(spa_texts)\n",
    "    que_texts = list(que_texts)\n",
    "    #Representa un conjunto potencialmente grande de elementos.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((spa_texts, que_texts))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n",
    "    return dataset.shuffle(2048).prefetch(16).cache()\n",
    "\n",
    "train_ds = make_dataset(train_pairs)\n",
    "val_ds = make_dataset(val_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'español': array([[  26,  307,   94, ..., 2387, 5011,  107],\n",
       "        [  45,   41,  122, ...,    4,  228,   10],\n",
       "        [  54,   33,   20, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [   7,  424,    2, ..., 1375,    3, 1116],\n",
       "        [ 168,  771, 1714, ..., 1027,   16,  109],\n",
       "        [   6,   89,   21, ...,  424,    2,    9]], dtype=int64),\n",
       " 'quechua': array([[    2,   770,    48, ..., 10910,  5551,     3],\n",
       "        [    2,     1,     1, ...,     0,     0,     0],\n",
       "        [    2,    59,     4, ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [    2,  1355,    22, ...,     0,     0,     0],\n",
       "        [    2,     8,  2096, ...,   494,   561,    38],\n",
       "        [    2,    33,   264, ...,     0,     0,     0]], dtype=int64)}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "example = list(train_ds.as_numpy_iterator())\n",
    "example[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = make_dataset(test_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aUCAbxB1cd_n",
    "outputId": "d3957fda-644d-4c03-9967-85f3db4fc405"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs['español'].shape: (100, 20)\n",
      "inputs['quechua'].shape: (100, 20)\n",
      "targets.shape: (100, 20)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds.take(1):\n",
    "    print(f\"inputs['español'].shape: {inputs['español'].shape}\")\n",
    "    print(f\"inputs['quechua'].shape: {inputs['quechua'].shape}\")\n",
    "    print(f\"targets.shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4EYWmSldcd_v"
   },
   "source": [
    "### Sequence-to-sequence learning with Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "bVayEf57mbKU"
   },
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential([layers.Dense(dense_dim, activation=\"relu\"),layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask[:, tf.newaxis, :]\n",
    "        attention_output = self.attention(inputs, inputs, attention_mask=mask)\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KI-aCOmpcd_w"
   },
   "source": [
    "#### The Transformer decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lnKhcitHcd_x"
   },
   "source": [
    "**The `TransformerDecoder`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "VzNdRzz_cd_y"
   },
   "outputs": [],
   "source": [
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.attention_2 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential([layers.Dense(dense_dim, activation=\"relu\"),layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat([tf.expand_dims(batch_size, -1),tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
    "        return tf.tile(mask, mult)\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
    "        attention_output_1 = self.attention_1(query=inputs,value=inputs,key=inputs,attention_mask=causal_mask)\n",
    "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "        attention_output_2 = self.attention_2(query=attention_output_1,value=encoder_outputs,key=encoder_outputs,attention_mask=padding_mask,)\n",
    "        attention_output_2 = self.layernorm_2(attention_output_1 + attention_output_2)\n",
    "        proj_output = self.dense_proj(attention_output_2)\n",
    "        return self.layernorm_3(attention_output_2 + proj_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BD7b3HMKcd_z"
   },
   "source": [
    "#### Putting it all together: A Transformer for machine translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ArKtxCmAcd_z"
   },
   "source": [
    "**PositionalEmbedding layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "vLFd6WhNcd_0"
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(input_dim=input_dim, output_dim=output_dim)\n",
    "        self.position_embeddings = layers.Embedding(input_dim=sequence_length, output_dim=output_dim)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(PositionalEmbedding, self).get_config()\n",
    "        config.update({\n",
    "            \"output_dim\": self.output_dim,\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "            \"input_dim\": self.input_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6nfZSDkcd_0"
   },
   "source": [
    "**End-to-end Transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "1rRYwvr4cd_1"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "embed_dim = 256\n",
    "dense_dim = 2048\n",
    "num_heads = 8\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"español\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"quechua\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
    "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "leszOQ8mJO0W",
    "outputId": "a1da105c-be0f-4e5e-f797-298f2f316a3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "200/200 [==============================] - 258s 1s/step - loss: 6.4720 - accuracy: 0.2030\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 260s 1s/step - loss: 5.7770 - accuracy: 0.2526\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 258s 1s/step - loss: 5.3528 - accuracy: 0.2849\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 275s 1s/step - loss: 5.0230 - accuracy: 0.3078\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 277s 1s/step - loss: 4.7042 - accuracy: 0.3337\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 279s 1s/step - loss: 4.4471 - accuracy: 0.3555\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 284s 1s/step - loss: 4.1880 - accuracy: 0.3788\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 278s 1s/step - loss: 3.9563 - accuracy: 0.4004\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 277s 1s/step - loss: 3.7338 - accuracy: 0.4238\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 275s 1s/step - loss: 3.5224 - accuracy: 0.4477\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 277s 1s/step - loss: 3.3221 - accuracy: 0.4717\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 278s 1s/step - loss: 3.1359 - accuracy: 0.4968\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 273s 1s/step - loss: 2.9612 - accuracy: 0.5195\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 257s 1s/step - loss: 2.7891 - accuracy: 0.5438\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 257s 1s/step - loss: 2.6350 - accuracy: 0.5667\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 276s 1s/step - loss: 2.5045 - accuracy: 0.5852\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 256s 1s/step - loss: 2.3811 - accuracy: 0.6050\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 256s 1s/step - loss: 2.2767 - accuracy: 0.6200\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 254s 1s/step - loss: 2.1883 - accuracy: 0.6368\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 262s 1s/step - loss: 2.1123 - accuracy: 0.6495\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 258s 1s/step - loss: 2.0360 - accuracy: 0.6637\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 258s 1s/step - loss: 1.9773 - accuracy: 0.6739\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 258s 1s/step - loss: 1.9339 - accuracy: 0.6822\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 260s 1s/step - loss: 1.8950 - accuracy: 0.6914\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 261s 1s/step - loss: 1.8621 - accuracy: 0.6993\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 258s 1s/step - loss: 1.8365 - accuracy: 0.7044\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 260s 1s/step - loss: 1.8086 - accuracy: 0.7116\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 258s 1s/step - loss: 1.7834 - accuracy: 0.7191\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 263s 1s/step - loss: 1.7814 - accuracy: 0.7203\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 259s 1s/step - loss: 1.7627 - accuracy: 0.7258\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 264s 1s/step - loss: 1.7476 - accuracy: 0.7314\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 266s 1s/step - loss: 1.7415 - accuracy: 0.7351\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 262s 1s/step - loss: 1.7336 - accuracy: 0.7388\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 261s 1s/step - loss: 1.7254 - accuracy: 0.7434\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 270s 1s/step - loss: 1.7193 - accuracy: 0.7464\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 259s 1s/step - loss: 1.7218 - accuracy: 0.7471\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 258s 1s/step - loss: 1.7136 - accuracy: 0.7495\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 273s 1s/step - loss: 1.7079 - accuracy: 0.7524\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 280s 1s/step - loss: 1.7017 - accuracy: 0.7559\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 279s 1s/step - loss: 1.7004 - accuracy: 0.7580\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 285s 1s/step - loss: 1.7036 - accuracy: 0.7584\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 277s 1s/step - loss: 1.7038 - accuracy: 0.7602\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 275s 1s/step - loss: 1.7017 - accuracy: 0.7621\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 277s 1s/step - loss: 1.6906 - accuracy: 0.7647\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 278s 1s/step - loss: 1.6962 - accuracy: 0.7647\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 280s 1s/step - loss: 1.6935 - accuracy: 0.7671\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 279s 1s/step - loss: 1.6911 - accuracy: 0.7683\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 283s 1s/step - loss: 1.6890 - accuracy: 0.7694\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 281s 1s/step - loss: 1.6925 - accuracy: 0.7693\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 284s 1s/step - loss: 1.6856 - accuracy: 0.7727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28ac27964c0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])\n",
    "#transformer.fit(train_ds, epochs=30, validation_data=val_ds)\n",
    "transformer.fit(train_ds, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_AMSNPLcd_2"
   },
   "source": [
    "**Training the sequence-to-sequence Transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B3e9_cLicd_3",
    "outputId": "3c239659-2859-4d53-fad2-ff3decfd56b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Para empezar, Adán perdió su vida, pero no una vida como la nuestra, de 70 u 80 años: perdió la oportunidad de vivir para siempre.\n",
      "[start] qallarinapaq [UNK] [UNK] ichaqa manan kawsayninchispi [UNK] imaynan adanwan pichqa wata otaq [UNK] mana [UNK] chay hinatan sapa kutilla kawsayninta\n",
      "-\n",
      "La Biblia recomienda el equilibrio: nos anima a trabajar duro, pero también a disfrutar de los beneficios; ese es “el don de Dios ”.\n",
      "[start] biblian yanapawasun [UNK] chhaynata [UNK] [UNK] ichaqa sinchitan [UNK] allin takyasqa [UNK] [end]\n",
      "-\n",
      "Juliza comprobó que los consejos de la Palabra de Dios son muy sabios.\n",
      "[start] [UNK] [UNK] diospa simin qelqa paykunata ancha [UNK] [end]\n",
      "-\n",
      "b) ¿Qué debemos hacer si nos surgen deseos sexuales inmorales?\n",
      "[start] b imatan ruwananchis warmiqhari warmiqhari puñuypi [UNK] chayqa [end]\n",
      "-\n",
      "SIN duda alguna, la Biblia no tiene rival en la historia.\n",
      "[start] mana iskayrayaspa bibliapa [UNK] manam [UNK] [end]\n",
      "-\n",
      "En 1975 fui a Roma varias veces para hablar de lo que estaba aprendiendo. Mis superiores trataron de convencerme de que estaba equivocado, pero ninguno usó la Biblia.\n",
      "[start] kunanqa [UNK] llaqtapi askha kutipin [UNK] rirqani chaymi [UNK] [UNK] jehová diospa sutinpi propÓsito [end]\n",
      "-\n",
      "Con todo, Gordon empezó a estudiar la Biblia y enseguida se convenció de haber encontrado la verdad.\n",
      "[start] ichaqa chay [UNK] [UNK] usqhayllan [UNK] qallarirqan jehová diosta [UNK] [end]\n",
      "-\n",
      "¡Nombremos un cabeza, y volvámonos a Egipto! ” ¿Cómo afectó a Jehová la desobediencia de Israel?\n",
      "[start] [UNK] sutiyoq warmin israel runakunata prometesqa [UNK] jehová diosta [UNK] israel [UNK] [end]\n",
      "-\n",
      "Acepté la verdad enseguida y comenzamos una larga amistad.\n",
      "[start] chayllam [UNK] chay temamanta [UNK] [end]\n",
      "-\n",
      "Y muchas personas no se dan cuenta de que en realidad no todas las cosas que quieren son necesarias para vivir.\n",
      "[start] hinaspapas askha runakunan mana tukuy [UNK] kanku [UNK] [UNK] [UNK] [UNK] [UNK] [end]\n",
      "-\n",
      "Un hombre que aprendió esta lección fue Job.\n",
      "[start] chay [UNK] job librota [UNK] [end]\n",
      "-\n",
      "Durante incontables milenios, Jehová — “el Anciano de Días ” — ha ejercido su autoridad como Soberano sobre una inmensa y organizada familia de hijos espirituales.\n",
      "[start] kimsa chunka [UNK] jehová dios [UNK] [UNK] hatun atiyniyoq kapurqan [UNK] [UNK] [UNK] [end]\n",
      "-\n",
      "Agotado por su viaje bajo el ardiente sol, el profeta se sentó bajo un arbusto y le pidió a Dios que le quitara la vida.\n",
      "[start] [UNK] chay [UNK] [UNK] [UNK] [UNK] diosta mañakurqan [UNK] huk allpata [UNK] [UNK] [end]\n",
      "-\n",
      "• ¿Cómo puede el esposo imitar al Pastor Excelente?\n",
      "[start] • imaynatan qosapas allin yachachiq [UNK] [end]\n",
      "-\n",
      "Por ejemplo, le dicen al niño: “Mi cielo, ¿quieres recoger tu cuarto, por favor? ”.\n",
      "[start] ejemplopaq [UNK] churinta [UNK] [UNK] nispa ninku [end]\n",
      "-\n",
      "La expresión “se halla agitado ” traduce un verbo hebreo que originalmente significa“ borbotear ” o “hervir ”.\n",
      "[start] chay simiqa hebreo [UNK] nisqa simiqa hebreo [UNK] [UNK] otaq [UNK] nisqa simiqa [UNK] [UNK] [UNK] niyta munan [end]\n",
      "-\n",
      "¡Cuánto me alegro de no haber ido a la universidad! ”.\n",
      "[start] ¡anchatan agradecekuni hatun [UNK] [UNK] ” [end]\n",
      "-\n",
      "Volvamos a la comparación del viaje.\n",
      "[start] chay [UNK] yachasun [end]\n",
      "-\n",
      "La Biblia dice: “Si a alguno de ustedes le falta sabiduría [especialmente cuando enfrenta desafíos], pídasela a Dios, y él se la dará. Dios es generoso y nos da todo con agrado ”.\n",
      "[start] biblian nin “pipas [UNK] chayqa astawan diostan [UNK] [UNK] payqa [UNK] nispa [end]\n",
      "-\n",
      "No obstante, no dejó que lo perturbara aquella circunstancia, por frustrante que fuera.\n",
      "[start] ichaqa manan chay [UNK] [UNK] chhayna [UNK] [end]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "spa_vocab = target_vectorization.get_vocabulary()\n",
    "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
    "max_decoded_sentence_length = 20\n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = target_vectorization([decoded_sentence])[:, :-1]\n",
    "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
    "        ##predictions = new_model([tokenized_input_sentence, tokenized_target_sentence])\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = spa_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence\n",
    "\n",
    "test_spa_texts = [pair[0] for pair in test_pairs]\n",
    "#traduccion = []\n",
    "for i in range(0,20):\n",
    "    input_sentence = test_spa_texts[i]\n",
    "    print(\"-\")\n",
    "    print(input_sentence)\n",
    "    print(decode_sequence(input_sentence))\n",
    "    #traduccion.append(decode_sequence(input_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8bJqYy3cd_4"
   },
   "source": [
    "## Precision del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "transformer = keras.models.load_model('path_to_my_model.h5',custom_objects={'PositionalEmbedding': PositionalEmbedding,'TransformerEncoder': TransformerEncoder,'TransformerDecoder':TransformerDecoder})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1023/1023 [==============================] - 2531s 2s/step - loss: 2.7506 - accuracy: 0.6055 - val_loss: 4.3933 - val_accuracy: 0.4386\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ec62771460>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.fit(train_ds, epochs=1, validation_data=val_ds)\n",
    "#new_model.fit(train_ds, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_model.save('path_to_my_model.h5')\n",
    "transformer.save('path_to_my_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   8/1023 [..............................] - ETA: 40:10 - loss: 3.2924 - accuracy: 0.5112"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-781edbb72f3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1648\u001b[0m                         ):\n\u001b[0;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1650\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1651\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    910\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 912\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    913\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    132\u001b[0m       (concrete_function,\n\u001b[0;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[1;33m     return concrete_function._call_flat(\n\u001b[0m\u001b[0;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1745\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "transformer.fit(train_ds, epochs=1, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "wIc1flCWEnDW",
    "outputId": "afed9595-3951-4ad2-d8f2-c93284003273"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = range(0,30)\n",
    "x1 = [0.1960, 0.2768, 0.3209 , 0.3526, 0.3766, 0.3970, 0.4169, 0.4344, 0.4524, 0.4703 , 0.4874, 0.5064, 0.5220, 0.5384, 0.5554, 0.5719, 0.5875, 0.6020, 0.6180, 0.6312, 0.6451, 0.6582, 0.6695, 0.6798, 0.6885, 0.6981, 0.7049, 0.7129, 0.7191, 0.7247] \n",
    "x2 = [0.2965, 0.3120, 0.3697, 0.3499, 0.3935, 0.3906, 0.3741, 0.3908, 0.4092, 0.4083, 0.4037, 0.3983, 0.3723, 0.3861, 0.3707, 0.3928, 0.3810, 0.3903, 0.3686, 0.3828, 0.3737, 0.3959, 0.3900, 0.3755, 0.3715, 0.3790, 0.3873, 0.3934, 0.3775, 0.3813]\n",
    "#Generamos una grafica lineal para una recta en X\n",
    "plt.plot(x, x1, label='accuracy train')\n",
    "#Generamos otra grafica lineal para una X cuadratica\n",
    "plt.plot(x, x2, label='accuracy val')\n",
    "#Agregamos las etiquetas y añadimos una leyenda.\n",
    "plt.xlabel('Epocas')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(\"Precision de nuestro modelo\")\n",
    "plt.legend()\n",
    "plt.savefig('grafica_lineal.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
